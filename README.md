# Stability-Analysis-of-Word-Embeddings

Word Embeddings have been crucial in determing the context and sense of the words. Many famous word embeddings have been proposed till date, like GloVe, Word2Vec, FastText, but with variability of Datasets, the representation changes, and falters at certain use cases.

Hence, this experiment was proposed to test the stability of various word embeddings across varying Datasets like European Parliament, Song Lyrics, Wikipedia Datasets, etc, and across varying hyperparameters like No. of Dimensions (50d,100d, 300d), No. of neighbours, Context Vectors, Frequency of Words across State-of-the-Art Tasks.

Inspiration for the project: https://arxiv.org/pdf/1804.09692.pdf 
